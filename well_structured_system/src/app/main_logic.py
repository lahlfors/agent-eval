"""Core application logic for handling user requests.

This module contains the primary orchestration logic for the application.
It defines how user queries are processed, how tools are called, and how
caching is utilized to improve performance.
"""

import asyncio
import time
from .cache import Cache
from .tools import metadata_tool, report_tool, independent_tool

async def handle_request(query: str, cache: Cache) -> str:
    """Handles a user request by orchestrating sequential tool calls.

    This function processes a user's query by first checking a cache for a
    previously computed result. If the query is not found in the cache, it
    executes a sequence of tool calls: first the `metadata_tool` and then
    the `report_tool`. The final result is then stored in the cache for
    future requests before being returned.

    Args:
        query: The user's input query string.
        cache: An instance of the `Cache` class used for storing and
               retrieving results.

    Returns:
        The final result string generated by the tool pipeline.
    """
    print(f"\nHandling request for query: '{query}'")

    # 1. Check the cache first
    cached_result = await cache.get(query)
    if cached_result:
        return cached_result

    # 2. If not in cache, run the sequential tool pipeline
    print("  No cached result. Executing tool pipeline...")
    metadata = await metadata_tool(query)
    final_result = await report_tool(metadata)

    # 3. Store the result in the cache before returning
    await cache.set(query, final_result)

    return final_result

async def handle_parallel_request() -> list[str]:
    """Demonstrates running multiple independent tools concurrently.

    This function showcases the use of `asyncio.gather` to execute three
    instances of the `independent_tool` in parallel. It measures and prints
    the time taken to complete all tasks, demonstrating the efficiency of
    concurrent execution for non-dependent operations.

    Returns:
        A list of result strings from each of the independent tool calls.
    """
    print("\nHandling request to run 3 independent tools...")

    # Create tasks to be run concurrently
    tasks = [
        independent_tool(1),
        independent_tool(2),
        independent_tool(3),
    ]

    # Use asyncio.gather to run them in parallel
    start_time = time.time()
    print("  Starting parallel execution with asyncio.gather...")
    results = await asyncio.gather(*tasks)
    end_time = time.time()

    print(f"  Finished parallel execution in {end_time - start_time:.2f}s")
    print("  Results:")
    for res in results:
        print(f"    - {res}")

    return results
